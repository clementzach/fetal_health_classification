{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fetal_health = pd.read_csv('fetal_health.csv')\n",
    "\n",
    "fetal_health['histogram_tendency'] = fetal_health['histogram_tendency'].astype(str)\n",
    "fetal_health = pd.get_dummies(fetal_health)\n",
    "fetal_health.fetal_health = fetal_health.fetal_health.astype(int).astype(str) #make outcome categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "fetal_health.shape\n",
    "\n",
    "\n",
    "fetal_health, fetal_health_test = train_test_split(fetal_health, \n",
    "                                    test_size = .2) ## withold our test set\n",
    "\n",
    "fetal_health_train, fetal_health_validate = train_test_split(fetal_health, \n",
    "                                    test_size = .2) \n",
    "\n",
    "\n",
    "#We have 2126 observations, so .3 should give us some of each class in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1034, 24)\n",
      "(201, 24)\n",
      "(104, 24)\n"
     ]
    }
   ],
   "source": [
    "## Evaluate class imbalance\n",
    "\n",
    "fetal_health_train_1 = fetal_health_train.loc[fetal_health_train.fetal_health == '1']\n",
    "fetal_health_train_2 = fetal_health_train.loc[fetal_health_train.fetal_health == '2']\n",
    "fetal_health_train_3 = fetal_health_train.loc[fetal_health_train.fetal_health == '3']\n",
    "\n",
    "print(fetal_health_train_1.shape)\n",
    "print(fetal_health_train_2.shape)\n",
    "print(fetal_health_train_3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rebalance classes in the train set\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def rebalance_classes(input_df):\n",
    "    class_1 = input_df.loc[input_df.fetal_health == '1']\n",
    "    class_2 = input_df.loc[input_df.fetal_health == '2']\n",
    "    class_3 = input_df.loc[input_df.fetal_health == '3']\n",
    "    \n",
    "    class_2 = resample(class_2, n_samples = class_1.shape[0])\n",
    "    class_3 = resample(class_3, n_samples = class_1.shape[0])\n",
    "    \n",
    "    output_df = pd.concat([class_1, class_2, class_3], ignore_index = True)\n",
    "    return(output_df)\n",
    "    \n",
    "fetal_health_train = rebalance_classes(fetal_health_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "RandomForest_100 = RandomForestClassifier(\n",
    "n_estimators = 100, #I want to experiment with different values of this\n",
    "criterion = \"gini\" #I don't think this should perform too differently from entropy, but I want to try \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_100_fit = RandomForest_100.fit(X = fetal_health_train.drop('fetal_health', axis = 1), \n",
    "                  y = fetal_health_train.fetal_health)\n",
    "#In the future I might do cross validation here\n",
    "\n",
    "\n",
    "rf_100_preds = rf_100_fit.predict(X= fetal_health_validate.drop('fetal_health', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy:\n",
      "0.9442508710801394\n",
      "\n",
      "Accuracy in class 1:\n",
      "0.9805194805194806\n",
      "\n",
      "Accuracy in class 2:\n",
      "0.7647058823529411\n",
      "\n",
      "Accuracy in class 3:\n",
      "0.8409090909090909\n"
     ]
    }
   ],
   "source": [
    "## Overall accuracy\n",
    "import numpy as np\n",
    "\n",
    "agreement = (rf_100_preds == fetal_health_validate.fetal_health)\n",
    "\n",
    "print(\"Overall Accuracy:\")\n",
    "\n",
    "print(np.mean(agreement))\n",
    "\n",
    "for i in range(3):\n",
    "    my_class = str(i + 1)\n",
    "    print('')\n",
    "    print(\"Accuracy in class \" + my_class + \":\")\n",
    "    print(np.mean(agreement[fetal_health_validate.fetal_health == my_class]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[422,  12,   1],\n",
       "       [ 19,  64,   3],\n",
       "       [  1,   2,  50]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(fetal_health_validate.fetal_health, rf_100_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for training and accuracy without rebalancing.\n",
    "# I want to do a simulation study to see if rebalancing is worth it.\n",
    "\n",
    "def no_rebalancing():\n",
    "    fetal_health_train, fetal_health_validate = train_test_split(fetal_health, \n",
    "                                    test_size = .3) \n",
    "    RandomForest_100 = RandomForestClassifier(n_estimators = 100)\n",
    "    rf_100_fit = RandomForest_100.fit(X = fetal_health_train.drop('fetal_health', axis = 1), y = fetal_health_train.fetal_health)\n",
    "    rf_100_preds = rf_100_fit.predict(X= fetal_health_validate.drop('fetal_health', axis = 1))\n",
    "    agreement = (rf_100_preds == fetal_health_validate.fetal_health)\n",
    "    return([np.mean(agreement), \n",
    "           np.mean(agreement[fetal_health_validate.fetal_health == '1']),\n",
    "           np.mean(agreement[fetal_health_validate.fetal_health == '2']),\n",
    "           np.mean(agreement[fetal_health_validate.fetal_health == '3'])])\n",
    "    \n",
    "                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_rebalancing():\n",
    "    fetal_health_train, fetal_health_validate = train_test_split(fetal_health, \n",
    "                                    test_size = .3) \n",
    "    fetal_health_train = rebalance_classes(fetal_health_train)\n",
    "    \n",
    "    \n",
    "    RandomForest_100 = RandomForestClassifier(n_estimators = 100)\n",
    "    rf_100_fit = RandomForest_100.fit(X = fetal_health_train.drop('fetal_health', axis = 1), y = fetal_health_train.fetal_health)\n",
    "    rf_100_preds = rf_100_fit.predict(X= fetal_health_validate.drop('fetal_health', axis = 1))\n",
    "    agreement = (rf_100_preds == fetal_health_validate.fetal_health)\n",
    "    return([np.mean(agreement), \n",
    "           np.mean(agreement[fetal_health_validate.fetal_health == '1']),\n",
    "           np.mean(agreement[fetal_health_validate.fetal_health == '2']),\n",
    "           np.mean(agreement[fetal_health_validate.fetal_health == '3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_rebalancing_mat = np.matrix([\"overall\", \"1\", \"2\", '3'])\n",
    "\n",
    "no_rebalancing_mat = np.matrix([\"overall\", \"1\", \"2\", '3'])\n",
    "\n",
    "for i in range(100): #Do 100 replications to see what happens\n",
    "    with_rebalancing_mat = np.vstack([with_rebalancing_mat, with_rebalancing()])\n",
    "    no_rebalancing_mat = np.vstack([no_rebalancing_mat, no_rebalancing()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_rebalancing_df = pd.DataFrame(with_rebalancing_mat[1:,:])\n",
    "no_rebalancing_df = pd.DataFrame(no_rebalancing_mat[1:,:])\n",
    "\n",
    "mat_cols = [\"overall\", \"1\", \"2\", '3']\n",
    "\n",
    "with_rebalancing_df.columns = mat_cols\n",
    "no_rebalancing_df.columns = mat_cols\n",
    "\n",
    "for col in mat_cols:\n",
    "    with_rebalancing_df[col] = with_rebalancing_df[col].astype('float')\n",
    "    no_rebalancing_df[col] = no_rebalancing_df[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accracy without rebalancing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "overall    0.935314\n",
       "1          0.979382\n",
       "2          0.740907\n",
       "3          0.848591\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accracy without rebalancing\")\n",
    "no_rebalancing_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after rebalancing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "overall    0.926394\n",
       "1          0.977576\n",
       "2          0.699492\n",
       "3          0.828892\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy after rebalancing\")\n",
    "with_rebalancing_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it looks like oversampling was a good idea. We had a bit better accuracy on the minority classes, and a slight increase in overall accuracy. \n",
    "\n",
    "Now, let's train our final model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using the full training set from above\n",
    "RandomForest_100 = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "\n",
    "fetal_health = rebalance_classes(fetal_health)\n",
    "rf_100_fit = RandomForest_100.fit(X = fetal_health.drop('fetal_health', axis = 1), y = fetal_health.fetal_health)\n",
    "rf_100_preds = rf_100_fit.predict(X= fetal_health_test.drop('fetal_health', axis = 1))\n",
    "\n",
    "\n",
    "importances = rf_100_fit.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "important_labelled = pd.DataFrame(zip(fetal_health.columns[:-1], importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>histogram_mean</td>\n",
       "      <td>0.116926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mean_value_of_short_term_variability</td>\n",
       "      <td>0.103222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>percentage_of_time_with_abnormal_long_term_var...</td>\n",
       "      <td>0.098150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abnormal_short_term_variability</td>\n",
       "      <td>0.086904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>histogram_mode</td>\n",
       "      <td>0.081335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>histogram_median</td>\n",
       "      <td>0.070752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uterine_contractions</td>\n",
       "      <td>0.057534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accelerations</td>\n",
       "      <td>0.052281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline value</td>\n",
       "      <td>0.045603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>histogram_width</td>\n",
       "      <td>0.044200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mean_value_of_long_term_variability</td>\n",
       "      <td>0.039507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>histogram_variance</td>\n",
       "      <td>0.037330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>histogram_min</td>\n",
       "      <td>0.035373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>histogram_max</td>\n",
       "      <td>0.034615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prolongued_decelerations</td>\n",
       "      <td>0.026164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fetal_movement</td>\n",
       "      <td>0.025164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>histogram_number_of_peaks</td>\n",
       "      <td>0.023572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>light_decelerations</td>\n",
       "      <td>0.007688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fetal_health</td>\n",
       "      <td>0.003758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>histogram_tendency_0.0</td>\n",
       "      <td>0.003430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>histogram_tendency_-1.0</td>\n",
       "      <td>0.003282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>histogram_number_of_zeroes</td>\n",
       "      <td>0.002936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>severe_decelerations</td>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0         1\n",
       "17                                     histogram_mean  0.116926\n",
       "8                mean_value_of_short_term_variability  0.103222\n",
       "9   percentage_of_time_with_abnormal_long_term_var...  0.098150\n",
       "7                     abnormal_short_term_variability  0.086904\n",
       "16                                     histogram_mode  0.081335\n",
       "18                                   histogram_median  0.070752\n",
       "3                                uterine_contractions  0.057534\n",
       "1                                       accelerations  0.052281\n",
       "0                                      baseline value  0.045603\n",
       "11                                    histogram_width  0.044200\n",
       "10                mean_value_of_long_term_variability  0.039507\n",
       "19                                 histogram_variance  0.037330\n",
       "12                                      histogram_min  0.035373\n",
       "13                                      histogram_max  0.034615\n",
       "6                            prolongued_decelerations  0.026164\n",
       "2                                      fetal_movement  0.025164\n",
       "14                          histogram_number_of_peaks  0.023572\n",
       "4                                 light_decelerations  0.007688\n",
       "20                                       fetal_health  0.003758\n",
       "22                             histogram_tendency_0.0  0.003430\n",
       "21                            histogram_tendency_-1.0  0.003282\n",
       "15                         histogram_number_of_zeroes  0.002936\n",
       "5                                severe_decelerations  0.000275"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_labelled.sort_values(1, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy:\n",
      "0.9389671361502347\n",
      "\n",
      "Accuracy in class 1:\n",
      "0.9882352941176471\n",
      "\n",
      "Accuracy in class 2:\n",
      "0.6896551724137931\n",
      "\n",
      "Accuracy in class 3:\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "agreement = (rf_100_preds == fetal_health_test.fetal_health)\n",
    "\n",
    "print(\"Overall Accuracy:\")\n",
    "\n",
    "print(np.mean(agreement))\n",
    "\n",
    "for i in range(3):\n",
    "    my_class = str(i + 1)\n",
    "    print('')\n",
    "    print(\"Accuracy in class \" + my_class + \":\")\n",
    "    print(np.mean(agreement[fetal_health_test.fetal_health == my_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
