{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get data\n",
    "import pandas as pd\n",
    "\n",
    "fetal_health = pd.read_csv('fetal_health.csv')\n",
    "\n",
    "fetal_health.histogram_tendency = fetal_health.histogram_tendency.astype('int').astype('str')\n",
    "\n",
    "fetal_health = pd.get_dummies(fetal_health) ## I need to figure out how to get this to work when only passing one obs\n",
    "\n",
    "fetal_health.fetal_health = fetal_health.fetal_health.astype('int').astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fetal_health, fetal_health_test = train_test_split(fetal_health, \n",
    "                                    test_size = .2) ## withold our test set\n",
    "\n",
    "fetal_health_train, fetal_health_validate = train_test_split(fetal_health, \n",
    "                                    test_size = .2, ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility_functions import rebalance_classes\n",
    "\n",
    "fetal_health_train = rebalance_classes(fetal_health_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "fetal_health_train_scaler = scale.fit(X = fetal_health_train.drop('fetal_health', axis = 1).to_numpy())\n",
    "\n",
    "fetal_health_train_x = fetal_health_train_scaler.transform(\\\n",
    "    X = fetal_health_train.drop('fetal_health', axis = 1).to_numpy())\n",
    "                                   \n",
    "\n",
    "fetal_health_validate_x = fetal_health_train_scaler.transform(\\\n",
    "    X = fetal_health_validate.drop('fetal_health', axis = 1).to_numpy())\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_y = pd.get_dummies(fetal_health_train.fetal_health).to_numpy()\n",
    "validate_y = pd.get_dummies(fetal_health_validate.fetal_health).to_numpy()\n",
    "\n",
    "train_tf_dataset = tf.data.Dataset.from_tensor_slices((fetal_health_train_x, train_y))\n",
    "validate_tf_dataset = tf.data.Dataset.from_tensor_slices((fetal_health_validate_x, validate_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "train_tf_dataset = train_tf_dataset.shuffle(buffer_size = fetal_health_train_x.shape[0]).batch(BATCH_SIZE)\n",
    "\n",
    "validate_tf_dataset = validate_tf_dataset.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(23, input_dim=23, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(3, activation = 'softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "              loss='categorical_crossentropy') #use because classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fa7b4a15e60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fa7b4a15e60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "319/319 [==============================] - 5s 15ms/step - loss: 0.5906 - val_loss: 0.0000e+00\n",
      "Epoch 2/20\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.3744 - val_loss: 0.3198\n",
      "Epoch 3/20\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.3093 - val_loss: 0.2930\n",
      "Epoch 4/20\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.2698 - val_loss: 0.2660\n",
      "Epoch 5/20\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 0.2327 - val_loss: 0.3011\n",
      "Epoch 6/20\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 0.2153 - val_loss: 0.2527\n",
      "Epoch 7/20\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.2008 - val_loss: 0.2788\n",
      "Epoch 8/20\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.1810 - val_loss: 0.2495\n",
      "Epoch 9/20\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.1685 - val_loss: 0.2706\n",
      "Epoch 10/20\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.1586 - val_loss: 0.2677\n",
      "Epoch 11/20\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 0.1508 - val_loss: 0.2573\n",
      "Epoch 12/20\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 0.1403 - val_loss: 0.2829\n",
      "Epoch 13/20\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 0.1386 - val_loss: 0.2422\n",
      "Epoch 14/20\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 0.1287 - val_loss: 0.3063\n",
      "Epoch 15/20\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 0.1262 - val_loss: 0.3244\n",
      "Epoch 16/20\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 0.1153 - val_loss: 0.2560\n",
      "Epoch 17/20\n",
      "319/319 [==============================] - 1s 5ms/step - loss: 0.1235 - val_loss: 0.2717\n",
      "Epoch 18/20\n",
      "319/319 [==============================] - 1s 4ms/step - loss: 0.1137 - val_loss: 0.2767\n",
      "Epoch 19/20\n",
      "319/319 [==============================] - 1s 5ms/step - loss: 0.1093 - val_loss: 0.2395\n",
      "Epoch 20/20\n",
      "319/319 [==============================] - 2s 7ms/step - loss: 0.1089 - val_loss: 0.2826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa7b49b4110>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_tf_dataset, \n",
    "          validation_data = validate_tf_dataset,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_preds = model.predict(validate_tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.apply_along_axis(np.argmax, 1, raw_preds) + 1\n",
    "\n",
    "preds = preds.transpose()\n",
    "\n",
    "preds = pd.DataFrame(preds, columns = ['preds'], dtype = 'str')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.9088235294117647\n",
      "Accuracy for class 1: 0.9266409266409267\n",
      "Accuracy for class 2: 0.8771929824561403\n",
      "Accuracy for class 3: 0.7916666666666666\n",
      "Weighted Accuracy: 0.8651668585879112\n",
      "Macro F1 score: 0.8492328927111537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utility_functions import accuracy_by_class\n",
    "from utility_functions import print_metrics\n",
    "\n",
    "\n",
    "if 'level_0' in fetal_health_validate.columns: ## The reset_index function \n",
    "    ## creates this column and creates an error if it's already there\n",
    "    fetal_health_validate.drop('level_0', axis = 1, inplace = True)\n",
    "\n",
    "fetal_health_validate = fetal_health_validate.reset_index() \n",
    "\n",
    "\n",
    "\n",
    "print(print_metrics(accuracy_by_class(preds.preds.astype('str'), fetal_health_validate.fetal_health.astype('str'))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-112-ecf84786f158>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-112-ecf84786f158>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Does this do markdown? I guess so!\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#TODO: reduce overfitting by:\n",
    "# 1. Data augmentation instead of just oversampling\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
