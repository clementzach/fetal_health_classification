{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get data\n",
    "import pandas as pd\n",
    "\n",
    "fetal_health = pd.read_csv('fetal_health.csv')\n",
    "\n",
    "fetal_health.histogram_tendency = fetal_health.histogram_tendency.astype('int').astype('str')\n",
    "\n",
    "fetal_health = pd.get_dummies(fetal_health) ## I need to figure out how to get this to work when only passing one obs\n",
    "\n",
    "fetal_health.fetal_health = fetal_health.fetal_health.astype('int').astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fetal_health, fetal_health_test = train_test_split(fetal_health, \n",
    "                                    test_size = .2) ## withold our test set\n",
    "\n",
    "fetal_health_train, fetal_health_validate = train_test_split(fetal_health, \n",
    "                                    test_size = .2) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility_functions import rebalance_classes\n",
    "\n",
    "fetal_health_train = rebalance_classes(fetal_health_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "fetal_health_train_scaler = scale.fit(X = fetal_health_train.drop('fetal_health', axis = 1).to_numpy())\n",
    "\n",
    "fetal_health_train_x = fetal_health_train_scaler.transform(\\\n",
    "    X = fetal_health_train.drop('fetal_health', axis = 1).to_numpy())\n",
    "                                   \n",
    "\n",
    "fetal_health_validate_x = fetal_health_train_scaler.transform(\\\n",
    "    X = fetal_health_validate.drop('fetal_health', axis = 1).to_numpy())\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_y = pd.get_dummies(fetal_health_train.fetal_health).to_numpy()\n",
    "validate_y = pd.get_dummies(fetal_health_validate.fetal_health).to_numpy()\n",
    "\n",
    "train_tf_dataset = tf.data.Dataset.from_tensor_slices((fetal_health_train_x, train_y))\n",
    "validate_tf_dataset = tf.data.Dataset.from_tensor_slices((fetal_health_validate_x, validate_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "train_tf_dataset = train_tf_dataset.shuffle(buffer_size = fetal_health_train_x.shape[0]).batch(BATCH_SIZE)\n",
    "\n",
    "validate_tf_dataset = validate_tf_dataset.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(23, input_dim=23, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation = 'softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "              loss='categorical_crossentropy') #use because classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fa7d2b7e170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fa7d2b7e170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "317/317 [==============================] - 4s 13ms/step - loss: 0.5001 - val_loss: 0.0000e+00\n",
      "Epoch 2/20\n",
      "317/317 [==============================] - 1s 5ms/step - loss: 0.3140 - val_loss: 0.3207\n",
      "Epoch 3/20\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 0.2504 - val_loss: 0.2886\n",
      "Epoch 4/20\n",
      "317/317 [==============================] - 1s 4ms/step - loss: 0.2071 - val_loss: 0.2861\n",
      "Epoch 5/20\n",
      "317/317 [==============================] - 1s 4ms/step - loss: 0.1797 - val_loss: 0.3179\n",
      "Epoch 6/20\n",
      "317/317 [==============================] - 3s 10ms/step - loss: 0.1535 - val_loss: 0.2502\n",
      "Epoch 7/20\n",
      "317/317 [==============================] - 2s 5ms/step - loss: 0.1361 - val_loss: 0.3063\n",
      "Epoch 8/20\n",
      "317/317 [==============================] - 1s 4ms/step - loss: 0.1222 - val_loss: 0.2989\n",
      "Epoch 9/20\n",
      "317/317 [==============================] - 1s 5ms/step - loss: 0.1098 - val_loss: 0.3069\n",
      "Epoch 10/20\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 0.0968 - val_loss: 0.2368\n",
      "Epoch 11/20\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 0.0905 - val_loss: 0.3414\n",
      "Epoch 12/20\n",
      "317/317 [==============================] - 1s 4ms/step - loss: 0.0840 - val_loss: 0.3228\n",
      "Epoch 13/20\n",
      "317/317 [==============================] - 1s 4ms/step - loss: 0.0774 - val_loss: 0.3616\n",
      "Epoch 14/20\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 0.0736 - val_loss: 0.2931\n",
      "Epoch 15/20\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 0.0668 - val_loss: 0.3654\n",
      "Epoch 16/20\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 0.0644 - val_loss: 0.3152\n",
      "Epoch 17/20\n",
      "317/317 [==============================] - 2s 5ms/step - loss: 0.0602 - val_loss: 0.3014\n",
      "Epoch 18/20\n",
      "317/317 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.3766\n",
      "Epoch 19/20\n",
      "317/317 [==============================] - 1s 4ms/step - loss: 0.0549 - val_loss: 0.3032\n",
      "Epoch 20/20\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 0.0544 - val_loss: 0.3553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa7d1d9c210>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_tf_dataset, \n",
    "          validation_data = validate_tf_dataset,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3186"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Looks like our previous model was overfitting after 2 epochs, so let's see if we can reduce that a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1700, 21)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.833536</td>\n",
       "      <td>2.833079</td>\n",
       "      <td>-0.178197</td>\n",
       "      <td>-1.110651</td>\n",
       "      <td>-0.608517</td>\n",
       "      <td>-0.114396</td>\n",
       "      <td>-0.456346</td>\n",
       "      <td>-1.336023</td>\n",
       "      <td>0.021985</td>\n",
       "      <td>-0.745624</td>\n",
       "      <td>...</td>\n",
       "      <td>1.204357</td>\n",
       "      <td>-1.055394</td>\n",
       "      <td>0.966302</td>\n",
       "      <td>0.734261</td>\n",
       "      <td>-0.443921</td>\n",
       "      <td>-0.023776</td>\n",
       "      <td>0.376939</td>\n",
       "      <td>-0.002029</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>-0.310440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.129078</td>\n",
       "      <td>-0.517716</td>\n",
       "      <td>-0.229352</td>\n",
       "      <td>0.447382</td>\n",
       "      <td>0.909666</td>\n",
       "      <td>-0.114396</td>\n",
       "      <td>-0.456346</td>\n",
       "      <td>-1.394128</td>\n",
       "      <td>0.225727</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001679</td>\n",
       "      <td>-1.323008</td>\n",
       "      <td>-0.000711</td>\n",
       "      <td>-0.262977</td>\n",
       "      <td>1.114713</td>\n",
       "      <td>0.109241</td>\n",
       "      <td>-0.094123</td>\n",
       "      <td>0.050765</td>\n",
       "      <td>0.063792</td>\n",
       "      <td>1.203134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.531625</td>\n",
       "      <td>-0.517716</td>\n",
       "      <td>5.670473</td>\n",
       "      <td>-1.110651</td>\n",
       "      <td>-0.608517</td>\n",
       "      <td>-0.114396</td>\n",
       "      <td>2.413750</td>\n",
       "      <td>1.336828</td>\n",
       "      <td>-0.894852</td>\n",
       "      <td>-0.745624</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372022</td>\n",
       "      <td>-0.044406</td>\n",
       "      <td>-0.967724</td>\n",
       "      <td>-0.262977</td>\n",
       "      <td>-0.443921</td>\n",
       "      <td>-1.132251</td>\n",
       "      <td>-0.376761</td>\n",
       "      <td>-0.688357</td>\n",
       "      <td>0.343296</td>\n",
       "      <td>1.203134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.676017</td>\n",
       "      <td>3.838317</td>\n",
       "      <td>0.623224</td>\n",
       "      <td>-0.487438</td>\n",
       "      <td>-0.608517</td>\n",
       "      <td>-0.114396</td>\n",
       "      <td>-0.456346</td>\n",
       "      <td>-1.103601</td>\n",
       "      <td>-0.079885</td>\n",
       "      <td>-0.745624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.431353</td>\n",
       "      <td>1.342363</td>\n",
       "      <td>-0.595389</td>\n",
       "      <td>-0.443921</td>\n",
       "      <td>1.882801</td>\n",
       "      <td>1.978549</td>\n",
       "      <td>2.162543</td>\n",
       "      <td>-0.308879</td>\n",
       "      <td>1.203134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.279838</td>\n",
       "      <td>1.492761</td>\n",
       "      <td>-0.229352</td>\n",
       "      <td>1.693809</td>\n",
       "      <td>-0.608517</td>\n",
       "      <td>-0.114396</td>\n",
       "      <td>-0.456346</td>\n",
       "      <td>-2.091394</td>\n",
       "      <td>0.633210</td>\n",
       "      <td>-0.745624</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214384</td>\n",
       "      <td>0.936847</td>\n",
       "      <td>1.181194</td>\n",
       "      <td>-0.595389</td>\n",
       "      <td>-0.443921</td>\n",
       "      <td>1.040360</td>\n",
       "      <td>1.130638</td>\n",
       "      <td>1.106654</td>\n",
       "      <td>-0.402047</td>\n",
       "      <td>-0.310440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.776654</td>\n",
       "      <td>-0.517716</td>\n",
       "      <td>-0.229352</td>\n",
       "      <td>-0.799044</td>\n",
       "      <td>-0.608517</td>\n",
       "      <td>-0.114396</td>\n",
       "      <td>-0.456346</td>\n",
       "      <td>0.697668</td>\n",
       "      <td>-0.894852</td>\n",
       "      <td>-0.519078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.867455</td>\n",
       "      <td>1.026052</td>\n",
       "      <td>-0.215603</td>\n",
       "      <td>-0.927801</td>\n",
       "      <td>-0.443921</td>\n",
       "      <td>0.508292</td>\n",
       "      <td>0.612470</td>\n",
       "      <td>0.578710</td>\n",
       "      <td>-0.541798</td>\n",
       "      <td>-0.310440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.129078</td>\n",
       "      <td>0.487523</td>\n",
       "      <td>-0.109991</td>\n",
       "      <td>-0.799044</td>\n",
       "      <td>-0.608517</td>\n",
       "      <td>-0.114396</td>\n",
       "      <td>-0.456346</td>\n",
       "      <td>-0.232019</td>\n",
       "      <td>2.568756</td>\n",
       "      <td>-0.745624</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452073</td>\n",
       "      <td>-1.293273</td>\n",
       "      <td>1.127471</td>\n",
       "      <td>-0.927801</td>\n",
       "      <td>-0.443921</td>\n",
       "      <td>0.109241</td>\n",
       "      <td>0.188514</td>\n",
       "      <td>0.209149</td>\n",
       "      <td>0.017208</td>\n",
       "      <td>-0.310440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-1.236083</td>\n",
       "      <td>2.833079</td>\n",
       "      <td>-0.212301</td>\n",
       "      <td>-0.175831</td>\n",
       "      <td>-0.608517</td>\n",
       "      <td>-0.114396</td>\n",
       "      <td>-0.456346</td>\n",
       "      <td>-0.115808</td>\n",
       "      <td>0.836952</td>\n",
       "      <td>-0.745624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213490</td>\n",
       "      <td>-0.371490</td>\n",
       "      <td>-0.161880</td>\n",
       "      <td>0.734261</td>\n",
       "      <td>-0.443921</td>\n",
       "      <td>0.286597</td>\n",
       "      <td>0.141408</td>\n",
       "      <td>0.156354</td>\n",
       "      <td>-0.332171</td>\n",
       "      <td>1.203134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.229715</td>\n",
       "      <td>-0.517716</td>\n",
       "      <td>-0.212301</td>\n",
       "      <td>0.447382</td>\n",
       "      <td>0.302393</td>\n",
       "      <td>-0.114396</td>\n",
       "      <td>1.457051</td>\n",
       "      <td>0.232825</td>\n",
       "      <td>1.142564</td>\n",
       "      <td>-0.745624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889081</td>\n",
       "      <td>-1.114863</td>\n",
       "      <td>0.106735</td>\n",
       "      <td>0.069436</td>\n",
       "      <td>-0.443921</td>\n",
       "      <td>-0.245471</td>\n",
       "      <td>-1.318884</td>\n",
       "      <td>-1.005124</td>\n",
       "      <td>1.065346</td>\n",
       "      <td>-0.310440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.273470</td>\n",
       "      <td>3.503238</td>\n",
       "      <td>-0.229352</td>\n",
       "      <td>1.070596</td>\n",
       "      <td>-0.304880</td>\n",
       "      <td>-0.114396</td>\n",
       "      <td>-0.456346</td>\n",
       "      <td>-0.406335</td>\n",
       "      <td>0.021985</td>\n",
       "      <td>-0.745624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731443</td>\n",
       "      <td>-0.728309</td>\n",
       "      <td>0.429073</td>\n",
       "      <td>1.066673</td>\n",
       "      <td>-0.443921</td>\n",
       "      <td>0.641309</td>\n",
       "      <td>0.706682</td>\n",
       "      <td>0.684299</td>\n",
       "      <td>-0.308879</td>\n",
       "      <td>1.203134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.833536  2.833079 -0.178197 -1.110651 -0.608517 -0.114396 -0.456346   \n",
       "1   -0.129078 -0.517716 -0.229352  0.447382  0.909666 -0.114396 -0.456346   \n",
       "2   -0.531625 -0.517716  5.670473 -1.110651 -0.608517 -0.114396  2.413750   \n",
       "3    0.676017  3.838317  0.623224 -0.487438 -0.608517 -0.114396 -0.456346   \n",
       "4    1.279838  1.492761 -0.229352  1.693809 -0.608517 -0.114396 -0.456346   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "335  0.776654 -0.517716 -0.229352 -0.799044 -0.608517 -0.114396 -0.456346   \n",
       "336 -0.129078  0.487523 -0.109991 -0.799044 -0.608517 -0.114396 -0.456346   \n",
       "337 -1.236083  2.833079 -0.212301 -0.175831 -0.608517 -0.114396 -0.456346   \n",
       "338 -0.229715 -0.517716 -0.212301  0.447382  0.302393 -0.114396  1.457051   \n",
       "339  0.273470  3.503238 -0.229352  1.070596 -0.304880 -0.114396 -0.456346   \n",
       "\n",
       "           7         8         9   ...        11        12        13  \\\n",
       "0   -1.336023  0.021985 -0.745624  ...  1.204357 -1.055394  0.966302   \n",
       "1   -1.394128  0.225727  0.009529  ...  1.001679 -1.323008 -0.000711   \n",
       "2    1.336828 -0.894852 -0.745624  ... -0.372022 -0.044406 -0.967724   \n",
       "3   -1.103601 -0.079885 -0.745624  ...  0.236010  0.431353  1.342363   \n",
       "4   -2.091394  0.633210 -0.745624  ... -0.214384  0.936847  1.181194   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "335  0.697668 -0.894852 -0.519078  ... -0.867455  1.026052 -0.215603   \n",
       "336 -0.232019  2.568756 -0.745624  ...  1.452073 -1.293273  1.127471   \n",
       "337 -0.115808  0.836952 -0.745624  ...  0.213490 -0.371490 -0.161880   \n",
       "338  0.232825  1.142564 -0.745624  ...  0.889081 -1.114863  0.106735   \n",
       "339 -0.406335  0.021985 -0.745624  ...  0.731443 -0.728309  0.429073   \n",
       "\n",
       "           14        15        16        17        18        19        20  \n",
       "0    0.734261 -0.443921 -0.023776  0.376939 -0.002029  0.040500 -0.310440  \n",
       "1   -0.262977  1.114713  0.109241 -0.094123  0.050765  0.063792  1.203134  \n",
       "2   -0.262977 -0.443921 -1.132251 -0.376761 -0.688357  0.343296  1.203134  \n",
       "3   -0.595389 -0.443921  1.882801  1.978549  2.162543 -0.308879  1.203134  \n",
       "4   -0.595389 -0.443921  1.040360  1.130638  1.106654 -0.402047 -0.310440  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "335 -0.927801 -0.443921  0.508292  0.612470  0.578710 -0.541798 -0.310440  \n",
       "336 -0.927801 -0.443921  0.109241  0.188514  0.209149  0.017208 -0.310440  \n",
       "337  0.734261 -0.443921  0.286597  0.141408  0.156354 -0.332171  1.203134  \n",
       "338  0.069436 -0.443921 -0.245471 -1.318884 -1.005124  1.065346 -0.310440  \n",
       "339  1.066673 -0.443921  0.641309  0.706682  0.684299 -0.308879  1.203134  \n",
       "\n",
       "[340 rows x 21 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1700"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
